{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-cloud-aiplatform requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini model\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\",\n",
    "                        system_instruction=[\"\"\"You are a store support API assistant to help with online orders.\"\"\"])\n",
    "\n",
    "# Define the user's prompt in a Content object that we can reuse in model calls\n",
    "user_prompt_content = Content(\n",
    "    role=\"user\",\n",
    "    parts=[\n",
    "        Part.from_text(\"What's the status of my order ID #12345?. If the order is not shipped, can you return it?\"),\n",
    "        #Part.from_text(\"I want to return my order with ID #12345?\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function declarations\n",
    "get_order_status_func = FunctionDeclaration(\n",
    "    name=\"get_order_status\",\n",
    "    description=\"Retrieve the current status of an order by its order ID.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unique identifier of the order.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"order_id\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "initiate_return_func = FunctionDeclaration(\n",
    "    name=\"initiate_return\",\n",
    "    description=\"Initiate a return process for a given order ID.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unique identifier of the order to be returned.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"order_id\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "cancel_order_func = FunctionDeclaration(\n",
    "    name=\"cancel_order\",\n",
    "    description=\"Cancel the order if the order exists by its order ID and if the order is not shipped yet.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"order_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unique identifier of the order.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"order_id\"]\n",
    "    },\n",
    ")\n",
    "# Define the tools that include the above functions\n",
    "support_tool = Tool(\n",
    "    function_declarations=[get_order_status_func, initiate_return_func, cancel_order_func],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the prompt and instruct the model to generate content using the Tool that you just created\n",
    "response = model.generate_content(\n",
    "    user_prompt_content,\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    "    tools=[support_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dummy functions for each operation\n",
    "def get_order_status(args):\n",
    "    order_id = args.get(\"order_id\")\n",
    "    # Simulated response\n",
    "    return {\n",
    "        \"order_id\": order_id,\n",
    "        \"shipping_status\": \"Not Shipped\",\n",
    "        \"expected_delivery\": \"Next week\",\n",
    "        \"status\": \"Active\"\n",
    "    }\n",
    "\n",
    "def initiate_return(args):\n",
    "    order_id = args.get(\"order_id\")\n",
    "    reason = args.get(\"reason\", \"No reason provided\")\n",
    "    # Simulated response\n",
    "    return {\n",
    "        \"order_id\": order_id,\n",
    "        \"return_status\": \"Return initiated successfully.\",\n",
    "        \"return_label\": \"You will receive a return label shortly.\"\n",
    "    }\n",
    "\n",
    "def cancel_order(args):\n",
    "    order_id = args.get(\"order_id\")\n",
    "    # Simulated response\n",
    "    return {\n",
    "        \"order_id\": order_id,\n",
    "        \"status\": \"Cancelled\"\n",
    "    }\n",
    "\n",
    "# Map function names to their handlers\n",
    "function_handlers = {\n",
    "    \"get_order_status\": get_order_status,\n",
    "    \"initiate_return\": initiate_return,\n",
    "    \"cancel_order\": cancel_order,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      function_call {\n",
      "        name: \"get_order_status\"\n",
      "        args {\n",
      "          fields {\n",
      "            key: \"order_id\"\n",
      "            value {\n",
      "              string_value: \"12345\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.111328125\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0693359375\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.341796875\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.182617188\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.163085938\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.078125\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.068359375\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0346679688\n",
      "  }\n",
      "  avg_logprobs: -3.6684258912618347e-08\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 137\n",
      "  candidates_token_count: 13\n",
      "  total_token_count: 150\n",
      "}\n",
      "model_version: \"gemini-1.5-flash-001\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"get_order_status\"\n",
      "args {\n",
      "  fields {\n",
      "    key: \"order_id\"\n",
      "    value {\n",
      "      string_value: \"12345\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Your order #12345 is currently active and not shipped yet, expected delivery is next week. Since the order is not shipped, you can return it. Do you want to initiate the return process? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all the function calls in the model's response\n",
    "for function_call in response.candidates[0].function_calls:\n",
    "    print(function_call)\n",
    "    function_name = function_call.name\n",
    "    args = {key: value for key, value in function_call.args.items()}\n",
    "    \n",
    "    if function_name in function_handlers:\n",
    "        # Call the appropriate function with the extracted arguments\n",
    "        api_response = function_handlers[function_name](args)\n",
    "\n",
    "        # Return the dummy API response to Gemini so it can generate a model response or request another function call\n",
    "        response = model.generate_content(\n",
    "            [\n",
    "                user_prompt_content,  # User prompt\n",
    "                response.candidates[0].content,  # Function call response\n",
    "                Content(\n",
    "                    parts=[\n",
    "                        Part.from_function_response(\n",
    "                            name=function_call.name,\n",
    "                            response={\"content\": api_response},  # Return the function response to Gemini\n",
    "                        ),\n",
    "                    ],\n",
    "                ),\n",
    "            ],\n",
    "            tools=[support_tool],\n",
    "        )\n",
    "\n",
    "        # Get the model response and print it\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the prompt and instruct the model to generate content using the Tool that you just created\n",
    "response = model.generate_content(\n",
    "    user_prompt_content,\n",
    "    generation_config=GenerationConfig(temperature=0),\n",
    "    tools=[support_tool],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
